{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification example to show how to use Oboe for training and testing, in the context of AutoML, i.e., do model selection on the training set and then evaluate the performance of the selected model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "#Oboe modules; this will be simplified when Oboe becomes pip installable\n",
    "automl_path = '../automl/'\n",
    "sys.path.append(automl_path)\n",
    "from auto_learner import AutoLearner\n",
    "import util\n",
    "\n",
    "#import scikit-learn modules\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split dataset into training and test folds\n",
    "data = load_iris()\n",
    "x = np.array(data['data'])\n",
    "y = np.array(data['target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: a no-brainer use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the autolearner class\n",
    "m = AutoLearner(p_type='classification', runtime_limit=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.02391304347826088\n",
      "elapsed time: 9.078747034072876\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))    \n",
    "print(\"elapsed time: {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'greedy selection',\n",
       " 'base learners': {'kSVM': [{'C': 4, 'kernel': 'poly', 'coef0': 10},\n",
       "   {'C': 8, 'kernel': 'rbf', 'coef0': 10},\n",
       "   {'C': 2, 'kernel': 'rbf', 'coef0': 0},\n",
       "   {'C': 0.125, 'kernel': 'rbf', 'coef0': 10}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: build an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.0\n",
      "elapsed time: 10.359421014785767\n",
      "individual accuracies of selected models: [0.0, 0.0, 0.02391304347826088]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))\n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"individual accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'greedy selection',\n",
       " 'base learners': {'KNN': [{'n_neighbors': 15, 'p': 1},\n",
       "   {'n_neighbors': 7, 'p': 1}],\n",
       "  'ExtraTrees': [{'min_samples_split': 16, 'criterion': 'entropy'}]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: just select a collection of promising models without building an ensemble afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 7.911957025527954\n",
      "accuracies of selected models: [0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.0, 0.0, 0.0, 0.0, 0.02391304347826088, 0.0, 0.0, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.0, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.0, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.5, 0.5, 0.5, 0.5, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.04782608695652174, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.5, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.5, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088, 0.02391304347826088]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    " \n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not have a single accuracy value here if we do not build an ensemble, instead, we just have a collection of fitted models with individual accuracies reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': [{'n_neighbors': 1, 'p': 2},\n",
       "  {'n_neighbors': 1, 'p': 2},\n",
       "  {'n_neighbors': 1, 'p': 1},\n",
       "  {'n_neighbors': 3, 'p': 1},\n",
       "  {'n_neighbors': 3, 'p': 2},\n",
       "  {'n_neighbors': 5, 'p': 1},\n",
       "  {'n_neighbors': 5, 'p': 2},\n",
       "  {'n_neighbors': 7, 'p': 2},\n",
       "  {'n_neighbors': 7, 'p': 1},\n",
       "  {'n_neighbors': 9, 'p': 1},\n",
       "  {'n_neighbors': 9, 'p': 2},\n",
       "  {'n_neighbors': 11, 'p': 1},\n",
       "  {'n_neighbors': 11, 'p': 2},\n",
       "  {'n_neighbors': 13, 'p': 2},\n",
       "  {'n_neighbors': 13, 'p': 1},\n",
       "  {'n_neighbors': 15, 'p': 1},\n",
       "  {'n_neighbors': 15, 'p': 2}],\n",
       " 'ExtraTrees': [{'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 64, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 128, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 128, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'entropy'}],\n",
       " 'RF': [{'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1024, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'gini'}],\n",
       " 'DT': [{'min_samples_split': 2},\n",
       "  {'min_samples_split': 1e-05},\n",
       "  {'min_samples_split': 0.0001},\n",
       "  {'min_samples_split': 0.001},\n",
       "  {'min_samples_split': 4},\n",
       "  {'min_samples_split': 8},\n",
       "  {'min_samples_split': 0.01},\n",
       "  {'min_samples_split': 16},\n",
       "  {'min_samples_split': 32},\n",
       "  {'min_samples_split': 64},\n",
       "  {'min_samples_split': 128},\n",
       "  {'min_samples_split': 1024},\n",
       "  {'min_samples_split': 512}],\n",
       " 'GNB': [{}],\n",
       " 'AB': [{'n_estimators': 50, 'learning_rate': 1},\n",
       "  {'n_estimators': 50, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 100, 'learning_rate': 1},\n",
       "  {'n_estimators': 100, 'learning_rate': 1.5}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
